\cleardoublepage
\pagestyle{scrheadings}
\cleardoublepage
\chapter{Theory}\label{ch:theory}

# Definition of Terms

- big data
- big Earth data
- data cube
- \ac{ToA} vs. \ac{BoA} vs. \ac{SURF} calibration
- \ac{ESA} Level 1C - Level 2A
- semantic enrichment
- humanitarian "crisis"
- indicator
- livelihood
- spatially-explicit

# Indicators and evidence

- Indicators for "humanitarian crisis"
- \ac{EO} data and need for indicators
- Development of spatially-explicit indicators
- Indicators vs. evidence
- literature review of existing \ac{EO}-based indicators or sources of evidence



Indicator development is imperative to leveraging the potential of \ac{EO} data and transforming them into meaningful and actionable information, especially as big, open and free data sources, such as provided by the Sentinel-2 satellites, are collected over a longer timespan. Indicator extraction is necessary because the reflectance observed by a sensor is only a proxy for detecting, identifying and monitoring objects and processes, since pixels representing similar reflectance values can represent different objects, surfaces, etc. Optical \ac{EO} data does not contain direct measurements of most objects or events on Earth (i.e. mixed pixels or relatively slow events). Non-physical entities (e.g. political boundaries) also cannot be directly measured. Replicable extraction of generic \ac{EO}-based indicators can complement indicators or reports from other in-situ sources as evidence for consilience to support decision\-makers. Since much \ac{EO}-data is independent of political boundaries, if not global in coverage, indicators derived from them will especially be useful in supporting international initiatives in various thematic domains, such as the \ac{UN}' \acp{SDG}.

The challenge with \ac{EO} data is their necessity to be classified or interpreted in order to support meaningful analysis. Goals have been identified in the scope of various global initiatives, with the expressed purpose of improving the lives of people across the world and mitigating potential or inevitable risks and vulnerabilities. Multiple targets have been identified for each of these goals. In this context, indicators exist or are being developed in order to monitor targets and report on progress over time. Many of the developed indicators are based on official statistics on a regional, national or provincial level, but are not spatially explicit. Incorporating information derived from an objective base of constantly collected \ac{EO} data with existing indicators can offer spatially explicit evidence that informs future actions towards identified goals.


The \ac{UN} has identified 17 goals with many targets and related indicators for the 2030 Agenda for Sustainable Development. These goals are known as the \acp{SDG} *INSERT FIGURE*.



For example, night-time light \ac{EO} data integrated with the \ac{JRC} \ac{GHSL} and disaggregated population data were used to assess the humanitarian impact of the Syrian conflict [@corbaneMonitoringSyrianHumanitarian2016]. Information extracted from big Earth data is a promising source of spatially-explicit evidence.

# Livelihood-specific Evidence

- how can livelihood be addressed from an indicator perspective…
- some non-\ac{EO} livelihood security indicators (existing or envisioned in literature)
- existing or envisioned \ac{EO}-based livelihood indicators or sources of evidence


1. economic size, growth and distribution (using luminosity)
2. population size, growth and distribution
3. differences in geographic endowments (water, farmland, natural resources, etc.) -- affect on supply of public goods
4. size and growth of cities, their legal and illegal parts, slums, disribution of infrastructure and economic activity, etc.
5. density and quality of road networks
6. size, quality and change of land plots
7. weather, climate, droughts, crop failurse, food shortages, etc. potential disasters
8. infrastructure that could prevent natural disasters
9. forced displacement, razed villages, mass graves
10. humanitarian responses to disasters and conflicts
11. illegal crops (e.g. drugs)
12. reconstruction activity after conflict (e.g. build up of infrastructure)


- crop cycles (measure periods of seasonal stress -- low harvest)
- contribute spatially explicit information to existing vulnerability/risk/hazard assessment methods


Cropping intensity (FAO)
Amount cultivated land/land ownership (HKI)

\ac{GDP} growth has been estimated through measuring light emissions from satellite images.

## Open-data

on the other hand, allows the rapid generation of large-scale and small-scale maps that do not include only “static” geophysical parameters (such as terrain height and vegetal cover), but also dynamic ones (such as likely positions of icebergs in the Arctic Ocean) and man-made artefacts.

One existing transferable method for initial, generic semantic enrichment is automatic spectral categorisation of \ac{EO} data (i.e. preliminary classification). This moves away from application-based algorithms (e.g. water classifiers) and sample-based classifiers, which are often not transferable among multiple images at different spatio-temporal locations. Completely automated understanding of remotely sensed images is something for the future, but pre-classification can be understood as a first, fully automated step towards automated land cover classification [@baraldiOperationalAutomaticRemote2012].

# State-of-the-Art


Initial, generic semantic enrichment, e.g. automatic spectral categorisation (i.e. preliminary classification) into classes equal or inferior to land cover classes

Initial, generic semantic enrichment, e.g. automatic spectral categorisation (i.e. preliminary classification), increases automation of \ac{EO}-based indicator extraction. Applying generic, semantic enrichment moves away from application-based algorithms (e.g. water classifiers) and sample-based classifiers, which are often not transferable among multiple images at different spatio-temporal locations. Complete, automated remotely sensed image understanding is something for the future, Pre-classification can be understood as a first, fully automated step towards image understanding, which is envisioned to include land cover classification [@baraldiOperationalAutomaticRemote2012]. Automatically generated semantic enrichment transforms \ac{EO} images into meaningful information in an automated way.


----------------------------

# Taken from elsewhere...

Big Earth data holds high potential for migration and emergency preparedness and response, especially due to its inherent independence from national or other human-imposed borders. Development of large-scale, automated (repeatable and reliable) methods for extracting information from huge amounts of data is the current trend in the field. This information can be used to improve situational awareness as well as regular, temporal monitoring and identification of changes. Data with lower spatial resolutions can be exploited by moving away from "direct" information extraction towards indicator-based approaches, whereas \ac{VHR} data can be exploited using multi-scale approaches. Analysis of night-time lights data for various purposes related to conflicts, as well as using \ac{VHR} data for visual monitoring of areas (e.g. \ac{IDP} camps, borders) are application fields with considerable research that is also relevant for migration monitoring, but methods based on other data sources exist or are being actively explored (e.g. crisis indicator development). Particularly, methods to monitor phenomena or events that have historically resulted in migration would be a means to shift from measures reacting to migration to more prevention or preparedness measures.

Sentinel’s multi-spectral satellites, 2A and 2B, run as part of the Copernicus programme (formerly known as \ac{GMES}) led by the \ac{EU}, together at full operational capacity have a revisit time of 5 days over equatorial areas and a relatively high spatial resolution (10-60m) with 13 spectral bands. Offering data already calibrated to \ac{ToA} reflectance, with a collective total of around one \ac{TB} of data daily, the Sentinel-2 satellites are predominantly used to monitor water cover, vegetation, coastal areas, soils, natural disasters and other features of interest for land services. Landsat 5/7/8 are other multi-spectral instruments with relatively lower spatial resolutions, less frequent re-visit times and without pre-processed \ac{ToA} reflectance, that can be exploited in similar ways, especially where historical data are relevant for comparison.

The \ac{JPSS} from \ac{NASA} and the \ac{NOAA}. The \ac{JPSS} includes the \ac{VIIRS}, meant to replace the \ac{MODIS} and \ac{AVHRR} sensors for tasks such as night-time light analysis, active fire detection and climate change monitoring. These data are accessible to the general public, often via online archives (e.g. Sentinels Scientific Data Hub, \ac{USGS} Landsat archive).

Global \acp{NTL} data show the locations and brightness of light escaping into space. Most of these lights are electric and originate from human settlements, making \ac{NTL} a useful data source for bridging social science and remote sensing. Since 2011, \ac{NTL} data are being captured by the \ac{VIIRS} \ac{DNB}. \ac{NTL} data has been used as an indicator for various socio-economic factors, but also for applications directly relevant to migration, such as estimating the number of affected or displaced people in the case of a crisis [@corbaneMonitoringSyrianHumanitarian2016] or early damaged area estimation (Kohiyama et al. 2004). Pre-processing requires removal of background noise and solar or lunar light contamination, cloud cover screening and exclusion of non-electric light sources (e.g. volcanoes, fires) (Elvidge et al. 2017). For 40 years, data was collected using the \acp{DMSP} \ac{OLS}. Methods exist for inter-calibrating \ac{DMSP} with \ac{VIIRS} data in order to gain longer time-series of images for detecting changes before \ac{VIIRS} became operational in late 2011. Liet al. (2017) inter-calibrated \ac{DMSP}/\ac{OLS} and \ac{VIIRS} night-time light images in order to retrospectively analyse changes that occurred to human settlement areas during the course of the Syrian civil war. Corbane et al. (2016) developed a methodology to estimate the number of people affected during a crisis utilising \ac{NTL} data combined with the \ac{JRC}'s \ac{GHSL}. Syria was the use-case and they demonstrated that a satellite-derived indicator from \ac{NTL} data can potentially offer a relatively objective estimate of the number of people impacted by a humanitarian crisis in a timely manner. The establishment and growth of refugee or \ac{IDP} camps may also be able to be detected based on \ac{NTL} data. Most \ac{NTL} studies up to now have been based on a few dates or annual image composites. Further research in this field would include focusing more on temporal dynamics in \ac{NTL}, taking seasonal or hourly changes into consideration to better inform interpretations of results.

Conventional remotely sensed data (i.e. optical) are limited in the sense that they can only detect features that are visible (e.g. built structures, vegetation, agricultural fields, roads). These data sources can be utilised to monitor security of livelihood assets (e.g. food or water security), land conflicts, post-crisis structural damage assessment, climate change effects that could cause population pressures, and more, depending on their spatial resolution and temporal characteristics.

Free and open high resolution optical imagery (e.g. Sentinel-2, Landsat 5/7/8) lends itself well to information extraction for indicators due to the fact that pixels are mixed. One applied example comes from Tiede et al. (2014) in the scope of the \ac{EC}'s \ac{FP7} project \ac{G-SEXTANT}. They demonstrated an automatic post-classification land cover change detection method based on Landsat imagery, focusing on changes in agricultural areas in at the Syrian-Turkish border as a potential indicator for livelihood security and ultimately regional stability in areas where the regional climate mandates irrigation to support crops. Further exploration into indicators for crisis, whether natural disasters or man-made conflicts, is an expanding field of research, including the development of automated methods for pro-longed monitoring of areas. Indicators based on high resolution data have been envisioned for detecting or monitoring burnt villages; informal urban growth; the development or growth of refugee or \ac{IDP} camps (Wang et al. 2015) and their impact on the surrounding environment; changes in activity (e.g. new infrastructures such as roads or air fields); illicit crop establishment and growth (e.g. opium cultivation in Afghanistan); environment degradation; flood assessment or visible changes to water bodies; changes or loss of agricultural areas; deforestation or reforestation; and visible climate change or extreme weather event artefacts.

The ultimate aim of any data management system is to facilitate technical access and handling of data as rapidly as possible. Handling in this case refers also to typical and well-known database use-cases, which are including, but not limited to, projection (sub setting), selection (filtering) or joining (combining) of data. Typical applications of big \ac{EO} images do not require processing all available images in an archive, but is usually selective regarding the area-of-interest, the time interval, quality levels (e.g. cloud cover) of the images but also their content itself (e.g. based on the legend of a scene classification map, i.e. water, vegetation, fire). The selection (filtering) might precede further operations, e.g. finding vegetation peaks over multiple years (a combination of projection and joining). Current \ac{EO} image archives such as the \ac{ESA} Scientific Data Hub or the \ac{USGS} Earth Explorer do not provide these operators. Moreover, typical purely files-in-directories-based approaches are limited to fulfil the requirements for implementing all of these operators to reach the aforementioned aim. Typically, the files are referenced by their filenames only or by using a hierarchical folder-based system. These storage systems are reading the files sequentially and are therefore not suitable for managing, including processing, large amount of data.

Current big \ac{EO} image processing paradigms require systems “to bring the users to the data and not the data to the users” and allow “any query, any time”. These paradigms are putting heavy requirements on software and hardware, especially in petabyte-scaled applications with data-intensive operations, which will be common in a few years. Therefore, data- and infrastructure providers are seeking the solution in cloud-based systems, where currently different approaches are existing side-by-side and are outperforming traditional methods. Arguably, the current prevalent big \ac{EO} data handling approach is to use a map-reduce-approach (a prominent example is the Google Earth Engine, or Apache Hadoop as software package), or a database-approach, where native array databases are utilised (example technologies (in the sense of “tools”) are Rasdaman and SciDB). Some approaches, such as the \ac{AGDC}, are combining both approaches, mainly by implementing and retrofitting database properties (user management, indexing, etc.).

Array-database-based approaches usually come with properties, which are well-known from relational databases and can be exploited for handling large amount of \ac{EO} images as well. Core features of database systems are the centralised data management, improved data security, multi-user support, transparent query processing and the use of a declarative query language like \ac{SQL}. Array databases have been applied for handling big Earth data in recent years [Planthaber et al. 2012]. Examples are the EarthServer [Baumann et al. 2016], based on the Rasdaman database, and EarthDB which is based on the SciDB database.

Most of the currently available technology implement the so-called datacube. For example, an array database might instantiate \ac{OGC}-compliant datacubes, where the semantics of the axes are defined using \acp{CRS}, e.g., spatial coordinate reference systems, known by the harmonisation efforts by the \ac{EPSG}. For example, in a three-dimensional datacube, a one-dimensional time \ac{CRS} overlays the two-dimensional \ac{CRS}. In total six characteristics have been identified in the publicly available datacube manifesto (<https://groups.google.com/forum/#!topic/rasdaman-users/Q3Zg7Tbc1_8>).  

Besides the technology-driven strategies for performing searching and processing on the database level, user-driven requirements are leading to on-demand web-based online processing of big \ac{EO} data. In the last years, several technologies and standards, which can be used for online processing of \ac{EO} data, have been developed and made available to the community [Petcu et al. 2010]. Two \ac{OGC} standards are the \ac{WCPS} and the \ac{WPS}, while technology implementations are Google Earth Engine [Google Earth Engine Team2015] or the Jupyter notebooks. Other examples of web-based platforms, which have been explicitly designed for processing and analysing \ac{EO} data, include the Amazon Cloud \ac{AWS} for processing of Landsat-8 data, with a free access to the \ac{API} [Amazon 2016]. The \ac{AGDC} is using the \ac{NCI} to provide Landsat images in the petabyte scale together with processing capabilities over the internet [Evans et al. 2015]. The \ac{EODC}, a collaboration between the technical university of Vienna, the \ac{ZAMG} and other companies, pursues a similar approach [Wagner et al. 2014]. Big Earth Data is characterised by the (at least three) “V’s”: Volume, Velocity, Variety, where sometimes Veracity is added as fourth “V”. Taking into account these characteristics, compared to traditional \ac{EO} image processing pipelines, Big Earth Data-“ready” systems have to consider some additional constraints, which are imposed by the “any query, any time” requirement. The exploitation of the value of Big Earth Data involves automation, pre-processing, on-demand querying and compelling visualisation of the results. Massive processing power in the cloud and fast network connection is required, but not sufficient. Automation of intelligent workflows leading to pre-processing of data are important drivers for on-demand and ad-hoc querying to extract information in real time. Semantically enriched data allow also unexperienced users to formulate queries by means a high-level declarative language. Instead of having to translate an algorithm into software code manually, the query will be evaluated by the system and transformed into optimised physical access patterns. This approach can be realised by automatic (application independent) semantic enrichment of \ac{EO} images in Big \ac{EO} image databases, which are therefore “prepared” and “ready” for application specific queries in distributed array databases (with a declarative query language and a query optimiser). This approach avoids redundancy in data handling and repeated data (pre-) processing. The feasibility of this approach has been proven by Tiede et. al. [2016].

(IQ image stack) \ac{EO} image data are semantically enriched and stored as information layers in datacubes. In combination with declarative querying in array databases, ad hoc information extraction is possible by means of semantic querying


### Global night-time lights monitoring]()

Global night-time lights (NTL) data show the locations and brightness of light escaping into space. Most of these lights are electric and originate from human settlements, making NTL a useful data source for bridging social science and remote sensing. Since 2011, NTL data are being captured by the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB). NTL data has been used as an indicator for various socio-economic factors, but also for applications directly relevant to migration, such as estimating the number of affected or displaced people in the case of a crisis  (Corbane, Kemper, Freire, Louvrier, & Pesaresi, 2016) or early damaged area estimation  (Kohiyama, et al.,2004). Pre-processing requires removal of background noise and solar or lunar light contamination, cloud cover screening and exclusion of non-electric light sources (e.g. volcanoes, fires)  (Elvidge, Baugh, Zhizhin, Hsu, & Ghosh, 2017). For 40 years, data was collected using the Defence Meteorological Satellite Program (DMSP) Operational Line Scan System (OLS).Methods exist for inter-calibrating DMSP with VIIRS data in order to gain longer time-series of images for detecting changes before VIIRS became operational in late 2011. Li et al. (2017) inter-calibrated DMSP/OLS and VIIRS night-time light images in order to retrospectively analyse changes that occurred to human settlement areas during the course of the Syrian civil war.  (Corbane, Kemper, Freire, Louvrier, & Pesaresi, 2016)developed a methodology to estimate the number of people affected during a crisis utilising NTL data combined with the Joint Research Centre’s (JRC)Global Human Settlement Layer (GHSL). Syria was the use-case and they demonstrated that a satellite-derived indicator from NTL data can potentially offer a relatively objective estimate of the number of people impacted by a humanitarian crisis in a timely manner. The establishment and growth of refugee or IDP camps may also be able to be detected based on NTL data. Most NTL studies up to now have been based on a few dates or annual image composites. Further research in this field would include focusing more on temporal dynamics in NTL, taking seasonal or hourly changes into consideration to better inform interpretations of results.

### HR/VHR EO sources

Conventional remotely sensed data (i.e. optical) are limited in the sense that they can only detect features that are visible (e.g. built structures, vegetation, agricultural fields, roads). These data sources can be utilised to monitor security of livelihood assets (e.g. food or water security), land conflicts, post-crisis structural damage assessment, climate change effects that could cause population pressures, and more, depending on their spatial resolution and temporal characteristics.

Free and open high resolution optical imagery (e.g. Sentinel-2, Landsat 5/7/8) lends itself well to information extraction for indicators due to the fact that pixels are mixed. One applied example comes from (Tiede, Luethje, and Baraldi, 2014) in the scope of the EC-FP7 project G-SEXTANT (Geospatial services in support of EU external action). They demonstrated an automatic post-classification land cover change detection method based on Landsat imagery, focusing on changes in agricultural areas in at the Syrian-Turkish border as a potential indicator for livelihood security and ultimately regional stability in areas where the regional climate mandates irrigation to support crops. Further exploration into indicators for crisis, whether natural disasters or man-made conflicts, is an expanding field of research, including the development of automated methods for pro-longed monitoring of areas. Indicators based on high resolution data have been envisioned for detecting or monitoring: burnt villages; informal urban growth; the development or growth of refugee or IDP camps  (Wang, So, & Smith, 2015) and their impact on the surrounding environment; changes in activity (e.g. new infrastructures such as roads or airfields); illicit crop establishment and growth (e.g. opium cultivation in Afghanistan); environment degradation; flood assessment or visible changes to water bodies; changes or loss of agricultural areas; deforestation or reforestation; and visible climate change or extreme weather event artefacts.

VHR data can be used to monitor and map changes, including: IDP, temporary and refugee settlements (Laneve, Santilli, & Lingenfelder, 2006); damaged or burnt urban or village structures; characterizing slums; border surveillance; and more detailed analysis of any land cover change. One critical issue in the optical data series processing is that preliminary cloud masking is required and also an accurate detection of haze conditions. In particular clouds make the optical data useless, while areas in the image affected by haze should be radiometrically corrected in order to avoid discarding of information. Change detection using optical data is usually a bigger challenge with respect to the SAR CD, depending on the information depth to be analysed.

The years have also seen the birth of constellation with tens of micro EO satellites able to capture images of the Earth at an unprecedented pace. One image per day and maybe more is no more a chimera like it was in the early 2000 years. Constellation like Planet and Terra Bella/SkyBox (now merged Planetto Acquire Terra Bella from Google, Sign Multi-Year Data Contract, <https://www.planet.com/pulse/planet-to-acquire-terra-bella-from-google/>)offers HR and VHR data commonly with a business model based on subscription which is exactly focused on monitoring purposes. As shown before in (Adam Van Etter, 2016), there are several efforts in order to exploit data coming from traditional VHR missions like DigitalGlobe ones and new space missions like Planet in order to extract automatically objects.

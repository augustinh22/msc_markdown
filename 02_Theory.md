# Theoretical Framework



## Definition of Terms

- big data
- big Earth data
- data cube
- Top of Atmosphere vs. BOA vs. SURF calibration
- ESA Level 1C - Level 2A
- semantic enrichment
- humanitarian "crisis"
- indicator
- livelihood

## Indicators and evidence

- Indicators for "humanitarian crisis"
- EO data and need for indicators
- Development of spatially-explicit indicators
- Indicators vs. evidence
- literature review of existing EO-based indicators or sources of evidence



Indicator development is imperative to leveraging the potential of EO data and transforming them into meaningful and actionable information, especially as big, open and free data sources, such as provided by the Sentinel-2 satellites, are collected over a longer timespan. Indicator extraction is necessary because the reflectance observed by a sensor is only a proxy for detecting, identifying and monitoring objects and processes, since pixels representing similar reflectance values can represent different objects, surfaces, etc. Optical EO data does not contain direct measurements of most objects or events on Earth (i.e. mixed pixels or relatively slow events). Non-physical entities (e.g. political boundaries) also cannot be directly measured. Replicable extraction of generic EO-based indicators can complement indicators or reports from other in-situ sources as evidence for consilience to support decision\-makers. Since much EO-data is independent of political boundaries, if not global in coverage, indicators derived from them will especially be useful in supporting international initiatives in various thematic domains, such as the United Nation's Sustainable Development goals.



## Livelihood-specific Evidence

- how can livelihood be addressed from an indicator perspective…
- some non-EO livelihood security indicators (existing or envisioned in literature)
- existing or envisioned EO-based livelihood indicators or sources of evidence




GDP growth has been estimated through measuring light emissions from satellite images.


## State-of-the-Art





----------------------------

# Taken from elsewhere...

Big Earth data holds high potential for migration and emergency preparedness and response, especially due to its inherent independence from national or other human-imposed borders. Development of large-scale, automated (repeatable and reliable) methods for extracting information from huge amounts of data is the current trend in the field. This information can be used to improve situational awareness as well as regular, temporal monitoring and identification of changes. Data with lower spatial resolutions can be exploited by moving away from "direct" information extraction towards indicator-based approaches, whereas VHR data can be exploited using multi-scale approaches. Analysis of night-time lights data for various purposes related to conflicts, as well as using VHR data for visual monitoring of areas (e.g. IDP camps, borders) are application fields with considerable research that is also relevant for migration monitoring, but methods based on other data sources exist or are being actively explored (e.g.crisis indicator development). Particularly, methods to monitor phenomena or events that have historically resulted in migration would be a means to shift from measures reacting to migration to more prevention or preparedness measures.

Global night-time lights (NTL) data show the locations and brightness of light escaping into space. Most of these lights are electric and originate from human settlements,making NTL a useful data source for bridging social science and remote sensing. Since 2011, NTL data are being captured by the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB). NTL data has been used as an indicator for various socio-economic factors, but also for applications directly relevant to migration, such as estimating the number of affected or displaced people in the case of a crisis (Corbane et al. 2016) or early damaged area estimation (Kohiyama et al. 2004). Pre-processing requires removal of background noise and solar or lunar light contamination, cloud cover screening and exclusion of non-electric light sources (e.g. volcanoes, fires) (Elvidge et al. 2017). For 40 years, data was collected using the Defence Meteorological Satellite Program (DMSP) Operational Line Scan System (OLS). Methods exist for inter-calibrating DMSP with VIIRS data in order to gain longer time-series of images for detecting changes before VIIRS became operational in late 2011. Liet al. (2017) inter-calibrated DMSP/OLS and VIIRS night-time light images in order to retrospectively analyse changes that occurred to human settlement areas during the course of the Syrian civil war. Corbane et al. (2016) developed a methodology to estimate the number of people affected during a crisis utilising NTL data combined with the Joint Research Centre’s (JRC)Global Human Settlement Layer (GHSL). Syria was the use-case and they demonstrated that a satellite-derived indicator from NTL data can potentially offer a relatively objective estimate of the number of people impacted by a humanitarian crisis in a timely manner. The establishment and growth of refugee or IDP camps may also be able to be detected based on NTL data. Most NTL studies up to now have been based on a few dates or annual image composites.Further research in this field would include focusing more on temporal dynamics in NTL, taking seasonal or hourly changes into consideration to better inform interpretations of results.

Conventional remotely sensed data (i.e. optical) are limited in the sense that they can only detect features that are visible (e.g. built structures, vegetation,agricultural fields, roads). These data sources can be utilised to monitor security of livelihood assets (e.g. food or water security), land conflicts, post-crisis structural damage assessment, climate change effects that could cause population pressures, and more, depending on their spatial resolution and temporal characteristics.

Free and open high resolution optical imagery (e.g. Sentinel-2, Landsat 5/7/8) lends itself well to information extraction for indicators due to the fact that pixels are mixed. One applied example comes from Tiede et al. (2014) in the scope of the EC-FP7 project G-SEXTANT (Geospatial services in support of EU external action). They demonstrated an automatic post-classification land cover change detection method based on Landsat imagery, focusing on changes in agricultural areas in at the Syrian-Turkish border as a potential indicator for livelihood security and ultimately regional stability in areas where the regional climate mandates irrigation to support crops. Further exploration into indicators for crisis, whether natural disasters or man-made conflicts, is an expanding field of research, including the development of automated methods for pro-longed monitoring of areas. Indicators based on high resolution data have been envisioned for detecting or monitoring:burnt villages; informal urban growth; the development or growth of refugee or IDP camps (Wang et al. 2015) and their impact on the surrounding environment; changes in activity (e.g. new infrastructures such as roads or air fields);illicit crop establishment and growth (e.g. opium cultivation in Afghanistan); environment degradation; flood assessment or visible changes to water bodies; changes or loss of agricultural areas; deforestation or reforestation; and visible climate change or extreme weather event artefacts.

The ultimate aim of any data management system is to facilitate technical access and handling of data as rapidly as possible. Handling in this case refers also to typical and well-known database use-cases, which are including, but not limited to, projection (sub setting), selection (filtering) or joining (combining) of data. Typical applications of big EO images do not require processing all available images in an archive, but is usually selective regarding the area-of-interest, the time interval, quality levels (e.g. cloud cover) of the images but also their content itself (e.g. based on the legend of a scene classification map, i.e. water, vegetation, fire). The selection (filtering) might precede further operations, e.g. finding vegetation peaks over multiple years (a combination of projection and joining). Current EO image archives such as the ESA Scientific Data Hub or the USGS EarthExplorer do not provide these operators. Moreover, typical purely files-in-directories-based approaches are limited to fulfil the requirements for implementing all of these operators to reach the aforementioned aim. Typically, the files are referenced by their filenames only or by using a hierarchical folder-based system. These storage systems are reading the files sequentially and are therefore not suitable for managing, including processing, large amount of data.

Current big EO image processing paradigms require systems “to bring the users to the data and not the data to the users” and allow “any query, any time”. These paradigms are putting heavy requirements on software and hardware, especially in petabyte-scaled applications with data-intensive operations, which will be common in a few years. Therefore, data- and infrastructure providers are seeking the solution in cloud-based systems, where currently different approaches are existing side-by-side and are outperforming traditional methods. Arguably, the current prevalent big EO data handling approach is to use a map-reduce-approach (a prominent example is the Google Earth Engine, or Apache Hadoop as software package), or a database-approach, where native array databases are utilised (example technologies (in the sense of “tools”) are Rasdaman and SciDB). Some approaches, such as the Australian Geoscience Data Cube, are combining both approaches, mainly by implementing and retrofitting database properties (user management, indexing, etc.).

Array-database-based approaches usually come with properties, which are well-known from relational databases and can be exploited for handling large amount of EO images as well. Core features of database systems are the centralised data management, improved data security, multi-user support, transparent query processing and the use of a declarative query language like SQL (Structured Query Language). Array databases have been applied for handling big Earth data in recent years [Planthaber et al. 2012].Examples are the EarthServer [Baumann et al. 2016], based on the Rasdaman database, and EarthDB which is based on the SciDB database.

Most of the currently available technology implement the so-called datacube. For example, an array database might instantiate OGC-compliant datacubes, where the semantics of the axes are defined using coordinate reference systems (CRS), e.g., spatial coordinate reference systems, known by the harmonisation efforts by the EPSG. For example,in a three-dimensional datacube, a one-dimensional time CRS overlays the two-dimensional CRS. In total six characteristics have been identified in the publicly available datacube manifesto (<https://groups.google.com/forum/#!topic/rasdaman-users/Q3Zg7Tbc1_8>).  

Besides the technology-driven strategies for performing searching and processing on the database level, user-driven requirements are leading to on-demand web-based online processing of big EO data. In the last years, several technologies and standards, which can be used for online processing of EO data, have been developed and made available to the community [Petcu et al. 2010]. Two OGC standards are the Web Coverage Processing Service (WCPS) and the Web Processing Service (WPS), while technology implementations are Google Earth Engine [Google Earth Engine Team2015] or the Jupyter notebooks. Other examples of web-based platforms, which have been explicitly designed for processing and analysing EO data, include the Amazon Cloud AWS (Amazon Web Service) for processing of Landsat-8 data, with a free access to the API [Amazon 2016]. The Australian Geoscience Data Cube(AGDC) is using the National Computational Infrastructure (NCI) to provide Landsat images in the petabyte scale together with processing capabilities over the internet [Evans et al. 2015]. The Austrian Earth Observation Data Centre for Water Resources Monitoring (EODC), a collaboration between the technical university of Vienna, the Austrian Meteorological Service (ZAMG) and other companies, pursues a similar approach [Wagner et al. 2014].Big Earth Data is characterised by the (at least three) “V’s”: Volume, Velocity, Variety, where sometimes Veracity is added as fourth “V”. Taking into account these characteristics, compared to traditional EO image processing pipelines, Big Earth Data-“ready” systems have to consider some additional constraints, which are imposed by the “any query, any time” requirement. The exploitation of the value of Big Earth Data involves automation, pre-processing, on-demand querying and compelling visualisation of the results. Massive processing power in the cloud and fast network connection is required, but not sufficient. Automation of intelligent workflows leading to pre-processing of data are important drivers for on-demand and ad-hoc querying to extract information in real time.Semantically enriched data allow also unexperienced users to formulate queries by means a high-level declarative language. Instead of having to translate an algorithm into software code manually, the query will be evaluated by the system and transformed into optimised physical access patterns. This approach can be realised by automatic (application independent) semantic enrichment of EO images in Big EO image databases, which are therefore “prepared” and “ready”for application specific queries in distributed array databases (with a declarative query language and a query optimiser). This approach avoids redundancy in data handling and repeated data (pre-) processing. The feasibility of this approach has been proven by Tiede et. al. [2016]. 

![figure_IQ_18042016_300dpi](file:///C:/Users/b1041827/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

[Figure ]()6: EO image data are semantically enriched and stored as information layers in datacubes. In combination with declarative querying in array databases, ad hoc information extraction is possible by means of semantic querying

 

[1.1.1      Global night-time lights monitoring]()

Global night-time lights (NTL) data show the locations and brightness of light escaping into space. Most of these lights are electric and originate from human settlements, making NTL a useful data source for bridging social science and remote sensing. Since 2011, NTL data are being captured by the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB). NTL data has been used as an indicator for various socio-economic factors, but also for applications directly relevant to migration, such as estimating the number of affected or displaced people in the case of a crisis  (Corbane, Kemper, Freire, Louvrier, & Pesaresi, 2016) or early damaged area estimation  (Kohiyama, et al.,2004). Pre-processing requires removal of background noise and solar or lunar light contamination, cloud cover screening and exclusion of non-electric light sources (e.g. volcanoes, fires)  (Elvidge, Baugh,Zhizhin, Hsu, & Ghosh, 2017). For 40 years, data was collected using the Defence Meteorological Satellite Program (DMSP) Operational Line Scan System (OLS).Methods exist for inter-calibrating DMSP with VIIRS data in order to gain longer time-series of images for detecting changes before VIIRS became operational in late 2011. Li et al. (2017) inter-calibrated DMSP/OLS and VIIRS night-time light images in order to retrospectively analyse changes that occurred to human settlement areas during the course of the Syrian civil war.  (Corbane, Kemper, Freire, Louvrier, & Pesaresi, 2016)developed a methodology to estimate the number of people affected during acrisis utilising NTL data combined with the Joint Research Centre’s (JRC)Global Human Settlement Layer (GHSL). Syria was the use-case and they demonstrated that a satellite-derived indicator from NTL data can potentially offer a relatively objective estimate of the number of people impacted by a humanitarian crisis in a timely manner. The establishment and growth of refugee or IDP camps may also be able to be detected based on NTL data. Most NTL studies up to now have been based on a few dates or annual image composites. Further research in this field would include focusing more on temporal dynamics in NTL,taking seasonal or hourly changes into consideration to better inform interpretations of results.

[1.1.2      HR/VHR EO sources]()

Conventional remotely sensed data (i.e. optical) are limited in the sense that they can only detect features that are visible (e.g. built structures, vegetation,agricultural fields, roads). These data sources can be utilised to monitor security of livelihood assets (e.g. food or water security), land conflicts, post-crisis structural damage assessment, climate change effects that could cause population pressures, and more, depending on their spatial resolution and temporal characteristics.

Free and open high resolution optical imagery (e.g. Sentinel-2, Landsat 5/7/8) lends itself well to information extraction for indicators due to the fact that pixels are mixed. One applied example comes from (Tiede, Luethje, and Baraldi, 2014) in the scope of the EC-FP7 project G-SEXTANT (Geospatial services in support of EU external action). They demonstrated an automatic post-classification land cover change detection method based on Landsat imagery, focusing on changes in agricultural areas in at the Syrian-Turkish border as a potential indicator for livelihood security and ultimately regional stability in areas where the regional climate mandates irrigation to support crops. Further exploration into indicators for crisis, whether natural disasters or man-made conflicts, is an expanding field of research, including the development of automated methods for pro-longed monitoring of areas.Indicators based on high resolution data have been envisioned for detecting or monitoring: burnt villages; informal urban growth; the development or growth of refugee or IDP camps  (Wang, So, & Smith, 2015) and their impact on the surrounding environment; changes in activity (e.g. new infrastructures such as roads or airfields); illicit crop establishment and growth (e.g. opium cultivation in Afghanistan); environment degradation; flood assessment or visible changes to water bodies; changes or loss of agricultural areas; deforestation or reforestation; and visible climate change or extreme weather event artefacts.

VHR data can be used to monitor and map changes, including: IDP, temporary and refugee settlements (Laneve, Santilli, & Lingenfelder, 2006); damaged or burnt urban or village structures; characterizing slums; border surveillance; and more detailed analysis of any land cover change. One critical issue in the optical data series processing is that preliminary cloud masking is required and also an accurate detection of haze conditions. In particular clouds make the optical data useless, while areas in the image affected by haze should be radiometrically corrected in order to avoid discarding of information. Change detection using optical data is usually a bigger challenge with respect to the SAR CD, depending on the information depth to be analysed.

The years have also seen the birth of constellation with tens of micro EO satellites able to capture images of the Earth at an unprecedented pace. One image per day and maybe more is no more a chimera like it was in the early 2000 years. Constellation like Planet and Terra Bella/SkyBox (now merged[[1\]](#_ftn1))offers HR and VHR data commonly with a business model based on subscription which is exactly focused on monitoring purposes. As shown before in (Adam Van Etter, 2016), there are several efforts in order to exploit data coming from traditional VHR missions like DigitalGlobe ones and new space missions like Planet in order to extract automatically objects.

------

[[1\]](#_ftnref1) Planetto Acquire Terra Bella from Google, Sign Multi-Year Data Contract, <https://www.planet.com/pulse/planet-to-acquire-terra-bella-from-google/>